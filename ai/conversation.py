import base64
import json
import logging
import time
import traceback
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Type

import requests

# OpenAI ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import (
    APIConnectionError,
    APIError,
    APIResponseValidationError,
    APIStatusError,
    APITimeoutError,
    AuthenticationError,
    BadRequestError,
    InternalServerError,
    NotFoundError,
    PermissionDeniedError,
    RateLimitError,
)
from openai.types.chat import (
    ChatCompletion,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionToolMessageParam,
)

from ai.client import get_client
from config import (
    OPENAI_MODEL,
    SYSTEM_PROMPT_FILENAME,
    SYSTEM_PROMPT_PATH,
)
from ai.tools import TOOL_DEFINITIONS, TOOL_FUNCTIONS
from log_utils.logger import logger
from utils.text_utils import truncate_text

# å®šæ•°ã®å®šç¾©
MAX_CONVERSATION_AGE_MINUTES = 30
MAX_CONVERSATION_TURNS = 10  # å¾€å¾©æ•°ã®ä¸Šé™
MAX_TOOL_CALL_ROUNDS = 3  # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®æœ€å¤§ãƒ©ã‚¦ãƒ³ãƒ‰æ•°ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_prompt_cache: dict[str, str] = {}


def _load_prompt_from_local(
    fail_on_error: bool = False,
) -> str | None:
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€

    Args:
        fail_on_error: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        str | None: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹

    Raises:
        RuntimeError: fail_on_error=Trueã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    prompt_path = Path(SYSTEM_PROMPT_PATH)

    logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿: {prompt_path}")
    try:
        prompt_content = prompt_path.read_text(encoding="utf-8").strip()
        logger.info("ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return prompt_content if prompt_content else None
    except Exception as e:
        error_msg = f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}"
        logger.error(error_msg, exc_info=True)

        if fail_on_error:
            raise RuntimeError(
                f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_msg}"
            ) from e

        return None


def _get_default_prompt() -> str:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—

    Returns:
        str: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    return "ã‚ãªãŸã¯å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"


def load_system_prompt(force_reload: bool = False, fail_on_error: bool = False) -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
    åˆå›ã®ã¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã€ä»¥é™ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã™ã‚‹

    Args:
        force_reload: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†èª­è¾¼ã™ã‚‹å ´åˆã¯True
        fail_on_error: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        str: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹

    Raises:
        RuntimeError: fail_on_error=Trueã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Šã€å¼·åˆ¶å†èª­è¾¼ã§ãªã„å ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™
    if SYSTEM_PROMPT_FILENAME in _prompt_cache and not force_reload:
        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ©ç”¨: {SYSTEM_PROMPT_FILENAME}")
        return _prompt_cache[SYSTEM_PROMPT_FILENAME]

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿
    prompt_content = _load_prompt_from_local(fail_on_error)

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not prompt_content:
        prompt_content = _get_default_prompt()
        logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    _prompt_cache[SYSTEM_PROMPT_FILENAME] = prompt_content

    return prompt_content


def reload_system_prompt(fail_on_error: bool = False) -> bool:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åˆ¶çš„ã«å†èª­ã¿è¾¼ã¿ã™ã‚‹

    Args:
        fail_on_error: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆã¯True

    Raises:
        RuntimeError: fail_on_error=Trueã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        load_system_prompt(force_reload=True, fail_on_error=fail_on_error)
        return True
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        if fail_on_error:
            raise
        return False


class Sphene:
    """AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä¼šè©±ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, system_setting: str) -> None:
        """Spheneã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–

        Args:
            system_setting: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.system: ChatCompletionSystemMessageParam = {
            "role": "system",
            "content": system_setting,
        }
        self.input_list: list[ChatCompletionMessageParam] = [self.system]
        self.logs: list[ChatCompletion] = []
        # ä¼šè©±ã®æœ‰åŠ¹æœŸé™ã‚’è¨­å®šï¼ˆ30åˆ†ï¼‰
        self.last_interaction: datetime | None = datetime.now()
        logger.info("Spheneã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–")

    def is_expired(self) -> bool:
        """ä¼šè©±ãŒæœŸé™åˆ‡ã‚Œã‹ã©ã†ã‹ã‚’åˆ¤å®š

        Returns:
            bool: Trueã®å ´åˆã¯æœŸé™åˆ‡ã‚Œ
        """
        if self.last_interaction is None:
            return False

        expiry_time = self.last_interaction + timedelta(
            minutes=MAX_CONVERSATION_AGE_MINUTES
        )
        return datetime.now() > expiry_time

    def update_interaction_time(self) -> None:
        """æœ€çµ‚ä¼šè©±æ™‚é–“ã‚’æ›´æ–°"""
        self.last_interaction = datetime.now()

    def trim_conversation_history(self) -> None:
        """é•·ããªã£ãŸä¼šè©±å±¥æ­´ã‚’æ•´ç†ã™ã‚‹

        ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒå£Šã‚Œãªã„ã‚ˆã†ã€
        å®‰å…¨ãªåˆ‡æ–­ãƒã‚¤ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã¦ãƒˆãƒªãƒŸãƒ³ã‚°ã™ã‚‹ã€‚
        """
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ + å¾€å¾©Nå›åˆ†ã ã‘ä¿æŒ
        max_messages = 1 + (MAX_CONVERSATION_TURNS * 2)

        if len(self.input_list) <= max_messages:
            return

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿æŒ
        system_message = self.input_list[0]
        # ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘ã‚’æ®‹ã™
        recent_messages = self.input_list[-(max_messages - 1) :]

        # å…ˆé ­ãŒtoolãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„tool_callsä»˜ãassistantã®å ´åˆã€
        # å®‰å…¨ãªé–‹å§‹ä½ç½®ï¼ˆuserãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã¾ã§é€²ã‚ã‚‹
        start_idx = 0
        for i, msg in enumerate(recent_messages):
            role = msg.get("role", "")
            if role == "user":
                start_idx = i
                break
            if role == "assistant" and "tool_calls" not in msg:
                start_idx = i
                break

        self.input_list = [system_message] + recent_messages[start_idx:]
        logger.info(
            f"ä¼šè©±å±¥æ­´ã‚’æ•´ç†ã—ã¾ã—ãŸï¼ˆæ®‹ã‚Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(self.input_list)}ï¼‰"
        )

    # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã¨å¯¾å¿œã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    _OPENAI_ERROR_HANDLERS: dict[Type[APIError], tuple[int, str, str]] = {
        AuthenticationError: (
            logging.ERROR,
            "OpenAI APIèªè¨¼ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®æ¥ç¶šè¨­å®šã§å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã¿ãŸã„â€¦ğŸ˜¢ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        PermissionDeniedError: (
            logging.ERROR,
            "OpenAI APIæ¨©é™ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã‚’ä½¿ã†ãŸã‚ã®æ¨©é™ãŒãªã„ã¿ãŸã„â€¦ğŸ˜¢ ç®¡ç†è€…ã«ç¢ºèªã—ã¦ã¿ã¦ã­ã€‚",
        ),
        NotFoundError: (
            logging.ERROR,
            "OpenAI APIãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚¨ãƒ©ãƒ¼: {}",
            f"ã”ã‚ã‚“ã­ã€æŒ‡å®šã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã€Œ{OPENAI_MODEL}ã€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã¿ãŸã„â€¦ğŸ˜¢",
        ),
        RateLimitError: (
            logging.WARNING,  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«
            "OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€ä»Šã¡ã‚‡ã£ã¨AIãŒæ··ã¿åˆã£ã¦ã‚‹ã¿ãŸã„â€¦ğŸ’¦ å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦è©±ã—ã‹ã‘ã¦ã¿ã¦ã­ï¼",
        ),
        APIConnectionError: (  # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã¯APIErrorã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã ãŒå€‹åˆ¥å‡¦ç†
            logging.ERROR,
            "OpenAI APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®æ¥ç¶šã§å•é¡ŒãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç¢ºèªã—ã¦ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        APITimeoutError: (  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚‚å€‹åˆ¥å‡¦ç†
            logging.ERROR,
            "OpenAI APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã‹ã‚‰ã®å¿œç­”ãŒæ™‚é–“å†…ã«è¿”ã£ã¦ã“ãªã‹ã£ãŸã¿ãŸã„â€¦ğŸ˜¢ ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã‚Œã‚‹ï¼Ÿ",
        ),
        InternalServerError: (
            logging.ERROR,
            "OpenAI APIã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIå´ã§ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã¿ãŸã„â€¦ğŸ˜¢ ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        APIStatusError: (  # ãã®ä»–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼
            logging.ERROR,
            "OpenAI APIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼ (Code: {}): {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®é€šä¿¡ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢",
        ),
        APIResponseValidationError: (
            logging.ERROR,
            "OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã‹ã‚‰ã®å¿œç­”ãŒãŠã‹ã—ã‹ã£ãŸã¿ãŸã„â€¦ğŸ¤” ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        BadRequestError: (
            logging.ERROR,
            "OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…å®¹ã«å•é¡ŒãŒã‚ã£ãŸã¿ãŸã„â€¦ğŸ˜¢ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¤‰ãˆã¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        # APIError ã¯ä¸Šè¨˜ä»¥å¤–ã®APIé–¢é€£ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒ
        APIError: (
            logging.ERROR,
            "OpenAI APIé–¢é€£ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®ã‚„ã‚Šå–ã‚Šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢",
        ),
    }

    def _handle_openai_error(self, error: Exception) -> str:
        """OpenAI APIã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™

        Args:
            error: å‡¦ç†ã™ã‚‹ã‚¨ãƒ©ãƒ¼

        Returns:
            str: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¡¨ç¤ºã™ã‚‹ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        error_body = getattr(error, "body", str(error))
        status_code = getattr(error, "status_code", None)

        for error_type, (
            level,
            log_template,
            user_msg,
        ) in self._OPENAI_ERROR_HANDLERS.items():
            if isinstance(error, error_type):
                log_args = [error_body]
                if error_type is APIStatusError and status_code is not None:
                    log_args.insert(0, status_code)  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å…ˆé ­ã«è¿½åŠ 
                logger.log(level, log_template.format(*log_args), exc_info=True)
                return user_msg

        # ãƒãƒƒãƒ”ãƒ³ã‚°ã«ãªã„äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
        tb_str = traceback.format_exc()
        logger.critical(
            f"APIå‘¼ã³å‡ºã—ä¸­ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼å‹ ({type(error).__name__}): {str(error)}\n{tb_str}"
        )
        return "ã”ã‚ã‚“ï¼AIã¨ã®é€šä¿¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

    def _execute_tool_calls(
        self, tool_calls: list,
    ) -> list[ChatCompletionToolMessageParam]:
        """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œã—ã€çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™

        Args:
            tool_calls: OpenAI APIã‹ã‚‰è¿”ã•ã‚ŒãŸtool_callsãƒªã‚¹ãƒˆ

        Returns:
            ãƒ„ãƒ¼ãƒ«çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
        """
        tool_messages: list[ChatCompletionToolMessageParam] = []

        for tool_call in tool_calls:
            function_name = tool_call.function.name
            tool_call_id = tool_call.id

            logger.info(f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {function_name}, ID: {tool_call_id}")

            func = TOOL_FUNCTIONS.get(function_name)
            if func is None:
                logger.warning(f"æœªçŸ¥ã®ãƒ„ãƒ¼ãƒ«é–¢æ•°: {function_name}")
                result_content = json.dumps(
                    {"error": f"æœªçŸ¥ã®é–¢æ•°: {function_name}"},
                    ensure_ascii=False,
                )
            else:
                try:
                    arguments = json.loads(tool_call.function.arguments)
                    logger.debug(f"ãƒ„ãƒ¼ãƒ«å¼•æ•°: {function_name}({arguments})")
                    result_content = func(**arguments)
                except json.JSONDecodeError as e:
                    logger.error(
                        f"ãƒ„ãƒ¼ãƒ«å¼•æ•°ã®JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {function_name}: {str(e)}",
                        exc_info=True,
                    )
                    result_content = json.dumps(
                        {"error": "å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ"},
                        ensure_ascii=False,
                    )
                except Exception as e:
                    logger.error(
                        f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {function_name}: {str(e)}",
                        exc_info=True,
                    )
                    result_content = json.dumps(
                        {"error": "ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"},
                        ensure_ascii=False,
                    )

            tool_message: ChatCompletionToolMessageParam = {
                "role": "tool",
                "tool_call_id": tool_call_id,
                "content": result_content,
            }
            tool_messages.append(tool_message)

        return tool_messages

    def _call_with_tool_loop(self) -> tuple[bool, str]:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚Œã°ãƒ«ãƒ¼ãƒ—å‡¦ç†ã™ã‚‹

        Returns:
            tuple[bool, str]: (æˆåŠŸãƒ•ãƒ©ã‚°, å¿œç­”å†…å®¹ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)

        Raises:
            OpenAI APIé–¢é€£ã®ä¾‹å¤–ã¯å‘¼ã³å‡ºã—å…ƒã«ä¼æ’­ã™ã‚‹
        """
        for round_num in range(MAX_TOOL_CALL_ROUNDS + 1):
            result = get_client().chat.completions.create(
                model=OPENAI_MODEL,
                messages=self.input_list,
                tools=TOOL_DEFINITIONS,
            )
            self.logs.append(result)

            message = result.choices[0].message

            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹å ´åˆ
            if message.tool_calls:
                logger.info(
                    f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æ¤œå‡ºï¼ˆãƒ©ã‚¦ãƒ³ãƒ‰ {round_num + 1}ï¼‰: "
                    f"{len(message.tool_calls)}ä»¶"
                )

                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆtool_callsä»˜ãï¼‰ã‚’å±¥æ­´ã«è¿½åŠ 
                assistant_tool_message: ChatCompletionAssistantMessageParam = {
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,  # type: ignore[union-attr]
                                "arguments": tc.function.arguments,  # type: ignore[union-attr]
                            },
                        }
                        for tc in message.tool_calls
                    ],
                }
                self.input_list.append(assistant_tool_message)

                # ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’è¿½åŠ 
                tool_messages = self._execute_tool_calls(message.tool_calls)
                for tool_msg in tool_messages:
                    self.input_list.append(tool_msg)

                continue

            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãªã— â†’ æœ€çµ‚å¿œç­”
            response_content = message.content
            if response_content:
                logger.debug(
                    f"OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {truncate_text(response_content)}"
                )
                return True, response_content
            else:
                logger.warning("OpenAI APIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™")
                return False, "ã”ã‚ã‚“ã­ã€AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã ã£ãŸã¿ãŸã„â€¦ğŸ¤”"

        # MAX_TOOL_CALL_ROUNDSã‚’è¶…ãˆãŸå ´åˆ
        logger.warning(
            f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒæœ€å¤§ãƒ©ã‚¦ãƒ³ãƒ‰æ•°({MAX_TOOL_CALL_ROUNDS})ã‚’è¶…é"
        )
        return False, "ã”ã‚ã‚“ã­ã€å‡¦ç†ãŒè¤‡é›‘ã™ãã¦ã†ã¾ãã„ã‹ãªã‹ã£ãŸã¿ãŸã„â€¦ğŸ˜¢"

    def _call_openai_api(
        self, with_images: bool = False, max_retries: int = 2
    ) -> tuple[bool, str]:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å‡¦ç†ã—ã€çµæœã‚’è¿”ã™

        ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯è‡ªå‹•çš„ã«å®Ÿè¡Œã—ã€çµæœã‚’æ·»ãˆã¦å†åº¦APIã‚’å‘¼ã¶ã€‚
        ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ï¼ˆæ¥ç¶šã‚¨ãƒ©ãƒ¼ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰ã®å ´åˆã¯
        æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§è‡ªå‹•çš„ã«å†è©¦è¡Œã—ã¾ã™ã€‚

        Args:
            with_images: ç”»åƒãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
            max_retries: ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼æ™‚ã®æœ€å¤§å†è©¦è¡Œå›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰

        Returns:
            tuple[bool, str]: (æˆåŠŸãƒ•ãƒ©ã‚°, å¿œç­”å†…å®¹ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
                - æˆåŠŸæ™‚: (True, AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ)
                - å¤±æ•—æ™‚: (False, ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)

        Note:
            å†è©¦è¡Œå¯èƒ½ãªã‚¨ãƒ©ãƒ¼: APIConnectionError, APITimeoutError, RateLimitError
            å¾…æ©Ÿæ™‚é–“: 2^è©¦è¡Œå›æ•° ç§’ï¼ˆ1å›ç›®=0.5ç§’ã€2å›ç›®=1ç§’ã€3å›ç›®=2ç§’ï¼‰
        """
        # å†è©¦è¡Œå¯¾è±¡ã®ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
        retry_error_types = (APIConnectionError, APITimeoutError, RateLimitError)

        for attempt in range(max_retries + 1):  # åˆå› + æœ€å¤§å†è©¦è¡Œå›æ•°
            try:
                # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
                if with_images:
                    log_msg = f"OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆãƒ¢ãƒ‡ãƒ«: {OPENAI_MODEL}, ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼‰"
                else:
                    log_msg = f"OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆãƒ¢ãƒ‡ãƒ«: {OPENAI_MODEL}, ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰"

                if attempt > 0:
                    logger.info(f"å†è©¦è¡Œ {attempt}/{max_retries}: {log_msg}")
                else:
                    logger.info(log_msg)

                # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ«ãƒ¼ãƒ—ï¼ˆå†…éƒ¨ã§APIå‘¼ã³å‡ºã—ãƒ»ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’å‡¦ç†ï¼‰
                return self._call_with_tool_loop()

            except retry_error_types as e:  # å†è©¦è¡Œå¯èƒ½ãªã‚¨ãƒ©ãƒ¼
                if attempt < max_retries:
                    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆå¾ã€…ã«å¾…æ©Ÿæ™‚é–“ã‚’å¢—ã‚„ã™ï¼‰
                    wait_time = (2**attempt) * 0.5  # 0.5ç§’, 1ç§’, 2ç§’...
                    logger.warning(
                        f"ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚å†è©¦è¡Œã—ã¾ã™ï¼ˆ{attempt + 1}/{max_retries}ï¼‰: "
                        f"{e.__class__.__name__}: {str(e)}. {wait_time}ç§’å¾Œã«å†è©¦è¡Œ"
                    )

                    time.sleep(wait_time)
                    continue
                else:
                    # å†è©¦è¡Œå›æ•°ã‚’è¶…ãˆãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼å‡¦ç†
                    user_message = self._handle_openai_error(e)
                    return False, user_message
            except APIError as e:  # ãã®ä»–ã®OpenAI APIé–¢é€£ã‚¨ãƒ©ãƒ¼
                user_message = self._handle_openai_error(e)
                return False, user_message
            except Exception as e:  # ãã®ä»–ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
                tb_str = traceback.format_exc()
                logger.critical(f"APIå‘¼ã³å‡ºã—ä¸­ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}\n{tb_str}")
                return (
                    False,
                    "ã”ã‚ã‚“ï¼AIã¨ã®é€šä¿¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢",
                )

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆç†è«–ä¸Šåˆ°é”ã—ãªã„ï¼‰
        logger.error("OpenAI APIå‘¼ã³å‡ºã—ãŒä¸å®Œå…¨çµ‚äº†ï¼šå…¨è©¦è¡Œå®Œäº†ã—ãŸãŒçµæœãŒä¸æ˜")
        return False, "ã”ã‚ã‚“ï¼AIã¨ã®é€šä¿¡ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

    def input_message(
        self, input_text: str | None, image_urls: list[str] | None = None
    ) -> str | None:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã€AIã‹ã‚‰ã®å¿œç­”ã‚’è¿”ã™

        Args:
            input_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            image_urls: æ·»ä»˜ç”»åƒã®URLãƒªã‚¹ãƒˆ

        Returns:
            str | None: AIã‹ã‚‰ã®å¿œç­”ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        """
        if not isinstance(input_text, str) or not input_text.strip():
            logger.warning("å—ä¿¡ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç„¡åŠ¹ã§ã™")
            return None

        try:
            self.update_interaction_time()
            # å‹ã‚¬ãƒ¼ãƒ‰ã‚’è¡Œã†
            input_str: str = input_text if isinstance(input_text, str) else ""
            preview = truncate_text(input_str)

            # ç”»åƒURLãƒªã‚¹ãƒˆã®å®‰å…¨ãªå‡¦ç†
            safe_image_urls: list[str] = (
                image_urls if isinstance(image_urls, list) else []
            )
            with_images = len(safe_image_urls) > 0

            # ç”»åƒä»˜ãã‹ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‹ã§ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¤‰æ›´
            if with_images:
                logger.debug(
                    f"ç”»åƒä»˜ããƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡: {preview}, ç”»åƒæ•°: {len(safe_image_urls)}"
                )
                # ç”»åƒå‡¦ç†
                processed_images = self._process_images(safe_image_urls)
                if processed_images:
                    # ãƒ†ã‚­ã‚¹ãƒˆ + ç”»åƒã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
                    # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å‹ãƒã‚§ãƒƒã‚¯ãŒå³å¯†ãªãŸã‚æ˜ç¤ºçš„ã«ç„¡è¦–ã™ã‚‹
                    content: list[dict[str, Any]] = [{"type": "text", "text": input_text}]  # type: ignore
                    for img in processed_images:
                        content.append(img)  # type: ignore

                    # å‹ãƒã‚§ãƒƒã‚¯ã‚’é€šã™ãŸã‚ã«ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹
                    user_message: ChatCompletionMessageParam = {
                        "role": "user",
                        "content": content,  # type: ignore
                    }
                else:
                    # ç”»åƒå‡¦ç†ã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§å‡¦ç†
                    logger.warning("ç”»åƒå‡¦ç†ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§å‡¦ç†ã—ã¾ã™")
                    user_message = {"role": "user", "content": input_text}
            else:
                # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                logger.debug(f"ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡: {preview}")
                user_message = {"role": "user", "content": input_text}

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            self.input_list.append(user_message)

            # OpenAI APIå‘¼ã³å‡ºã—ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            success, content_or_error_msg = self._call_openai_api(
                with_images=with_images
            )

            if success:
                # æˆåŠŸã—ãŸå ´åˆã€å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¿”ã™
                assistant_message: ChatCompletionAssistantMessageParam = {
                    "role": "assistant",
                    "content": content_or_error_msg,  # æˆåŠŸæ™‚ã¯å¿œç­”å†…å®¹
                }
                self.input_list.append(assistant_message)
                self.trim_conversation_history()
                return content_or_error_msg
            else:
                # å¤±æ•—ã—ãŸå ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
                # å¤±æ•—æ™‚ã¯APIå‘¼ã³å‡ºã—å´ã§ãƒ­ã‚°å‡ºåŠ›æ¸ˆã¿
                return content_or_error_msg  # å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        except Exception as e:
            # APIå‘¼ã³å‡ºã—ä»¥å¤–ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
            tb_str = traceback.format_exc()
            logger.critical(f"input_messageå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}\n{tb_str}")
            return "ã”ã‚ã‚“ï¼å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

    def _process_images(self, image_urls: list[str]) -> list[dict[str, Any]]:
        """ç”»åƒURLã‚’å‡¦ç†ã—ã¦OpenAI APIç”¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›

        å„ç”»åƒURLã«å¯¾ã—ã¦HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹ã‚’ç¢ºèª:
        - ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ï¼ˆ200 OKï¼‰: URLæ–¹å¼ã§é€ä¿¡
        - ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦é€ä¿¡ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

        Args:
            image_urls: ç”»åƒã®URLãƒªã‚¹ãƒˆ

        Returns:
            list[dict[str, Any]]: OpenAI APIãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç”»åƒãƒªã‚¹ãƒˆ
                å„è¦ç´ : {"type": "image_url", "image_url": {"url": <URLã¾ãŸã¯Data URI>}}

        Note:
            å¤±æ•—ã—ãŸç”»åƒã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã€ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒè¨˜éŒ²ã•ã‚Œã¾ã™
        """
        processed_images = []

        for url in image_urls:
            try:
                # ã¾ãšURLã¨ã—ã¦ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹ç¢ºèª
                response = requests.head(url, timeout=3)
                if response.status_code == 200:
                    # æˆåŠŸã—ãŸã‚‰ç›´æ¥URLæ–¹å¼
                    logger.debug(f"ç”»åƒå‡¦ç†: URLã¨ã—ã¦ä½¿ç”¨ - {url}")
                    processed_images.append(
                        {"type": "image_url", "image_url": {"url": url}}
                    )
                else:
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ãŒ200ä»¥å¤–ãªã‚‰Base64æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.debug(
                        f"ç”»åƒURLã‚¢ã‚¯ã‚»ã‚¹å¤±æ•— (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}) - Base64å¤‰æ›å®Ÿè¡Œ"
                    )
                    image_data = self._download_and_encode_image(url)
                    processed_images.append(
                        {"type": "image_url", "image_url": {"url": image_data}}
                    )
            except Exception as e:
                # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—æ™‚ã‚‚Base64æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                try:
                    logger.debug(f"ç”»åƒURLç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•— ({str(e)}) - Base64å¤‰æ›å®Ÿè¡Œ")
                    image_data = self._download_and_encode_image(url)
                    processed_images.append(
                        {"type": "image_url", "image_url": {"url": image_data}}
                    )
                except Exception as e2:
                    logger.error(f"ç”»åƒå‡¦ç†å®Œå…¨å¤±æ•—: {url} - {str(e2)}", exc_info=True)

        return processed_images

    def _download_and_encode_image(self, url: str) -> str:
        """ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹

        Args:
            url: ç”»åƒã®URL

        Returns:
            str: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        response = requests.get(url, timeout=5)
        response.raise_for_status()

        image_data = response.content
        image_b64 = base64.b64encode(image_data).decode("utf-8")

        # MIMEã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡ºï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰å–å¾—ã¾ãŸã¯URLã‹ã‚‰æ¨æ¸¬ï¼‰
        content_type = response.headers.get("Content-Type")
        if not content_type or not content_type.startswith("image/"):
            # URLã‹ã‚‰MIMEã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬
            if url.lower().endswith(".jpg") or url.lower().endswith(".jpeg"):
                content_type = "image/jpeg"
            elif url.lower().endswith(".png"):
                content_type = "image/png"
            elif url.lower().endswith(".gif"):
                content_type = "image/gif"
            elif url.lower().endswith(".webp"):
                content_type = "image/webp"
            else:
                content_type = "image/jpeg"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        logger.debug(f"ç”»åƒå‡¦ç†: Base64å¤‰æ›ã‚’ä½¿ç”¨ - MIME: {content_type}")
        return f"data:{content_type};base64,{image_b64}"


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ä¼šè©±ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¿æŒã™ã‚‹è¾æ›¸
user_conversations: defaultdict[str, Sphene] = defaultdict(
    lambda: Sphene(system_setting=load_system_prompt())
)


def generate_contextual_response(
    channel_context: str,
    trigger_message: str,
    system_prompt: str | None = None,
) -> str | None:
    """ãƒãƒ£ãƒ³ãƒãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã®1-shotå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹

    æ—¢å­˜ã®user_conversationsã¨ã¯ç‹¬ç«‹ã—ã¦å‹•ä½œã™ã‚‹ã€‚
    ä¼šè©±å±¥æ­´ã¯æŒãŸãšã€ãƒãƒ£ãƒ³ãƒãƒ«ã®æµã‚Œã‹ã‚‰1å›ã ã‘å¿œç­”ã™ã‚‹ã€‚

    Args:
        channel_context: ãƒãƒ£ãƒ³ãƒãƒ«ã®ç›´è¿‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        trigger_message: å¿œç­”ã®ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã£ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        system_prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆNoneã®å ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ï¼‰

    Returns:
        str | None: AIå¿œç­”ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    try:
        if system_prompt is None:
            system_prompt = load_system_prompt()

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        contextual_prompt = (
            f"{system_prompt}\n\n"
            f"--- ãƒãƒ£ãƒ³ãƒãƒ«ã®ç›´è¿‘ã®ä¼šè©± ---\n{channel_context}\n---\n\n"
            f"ä¸Šè¨˜ã®ä¼šè©±ã®æµã‚Œã‚’è¸ã¾ãˆã¦ã€è‡ªç„¶ã«ä¼šè©±ã«å‚åŠ ã—ã¦ãã ã•ã„ã€‚"
            f"ãƒªãƒ—ãƒ©ã‚¤ã§ã¯ãªãã€ä¼šè©±ã®ä¸€å‚åŠ è€…ã¨ã—ã¦è‡ªç„¶ã«ç™ºè¨€ã—ã¦ãã ã•ã„ã€‚"
        )

        messages: list[ChatCompletionMessageParam] = [
            {"role": "system", "content": contextual_prompt},
            {"role": "user", "content": trigger_message},
        ]

        logger.info("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’ç”Ÿæˆä¸­")
        result = get_client().chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
        )

        content = result.choices[0].message.content
        if content:
            logger.debug(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ç”Ÿæˆå®Œäº†: {truncate_text(content)}")
            return content
        else:
            logger.warning("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ãŒç©ºã§ã™")
            return None

    except Exception as e:
        # Spheneã®_handle_openai_errorã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ­ã‚°å‡ºåŠ›
        logger.error(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        return None


def cleanup_expired_conversations() -> int:
    """æœŸé™åˆ‡ã‚Œã®ä¼šè©±ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰å‰Šé™¤ã™ã‚‹

    Returns:
        int: å‰Šé™¤ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªæ•°
    """
    expired_ids = [
        user_id for user_id, api in user_conversations.items() if api.is_expired()
    ]
    for user_id in expired_ids:
        del user_conversations[user_id]

    if expired_ids:
        logger.info(f"æœŸé™åˆ‡ã‚Œã®ä¼šè©±ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: {len(expired_ids)}ä»¶")
    return len(expired_ids)
