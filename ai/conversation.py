import logging
import traceback
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import DefaultDict, Dict, List, Optional, Tuple, Type

# OpenAI ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import (
    APIConnectionError,
    APIError,
    APIResponseValidationError,
    APIStatusError,
    APITimeoutError,
    AuthenticationError,
    BadRequestError,
    InternalServerError,
    NotFoundError,
    PermissionDeniedError,
    RateLimitError,
)
from openai.types.chat import (
    ChatCompletion,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
)

from ai.client import client as aiclient
from config import (
    OPENAI_MODEL,
    PROMPT_STORAGE_TYPE,
    S3_BUCKET_NAME,
    S3_FOLDER_PATH,
    SYSTEM_PROMPT_FILENAME,
    SYSTEM_PROMPT_PATH,
)
from log_utils.logger import logger
from utils.s3_utils import S3Helper
from utils.text_utils import truncate_text

# å®šæ•°ã®å®šç¾©
MAX_CONVERSATION_AGE_MINUTES = 30
MAX_CONVERSATION_TURNS = 10  # å¾€å¾©æ•°ã®ä¸Šé™

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_prompt_cache: Dict[str, str] = {}


def _load_prompt_from_s3() -> tuple[Optional[str], List[str]]:
    """S3ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€

    Returns:
        tuple: (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ)
    """
    errors = []
    prompt_content = None

    if not S3_BUCKET_NAME:
        error_msg = "S3ãƒã‚±ãƒƒãƒˆåãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
        logger.warning(error_msg)
        errors.append(error_msg)
        return None, errors

    logger.info(f"S3ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿: {SYSTEM_PROMPT_FILENAME}")
    prompt_content = S3Helper.read_file_from_s3(
        S3_BUCKET_NAME, SYSTEM_PROMPT_FILENAME, S3_FOLDER_PATH
    )
    if prompt_content:
        logger.info("S3ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    else:
        error_msg = "S3ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
        logger.warning(error_msg)
        errors.append(error_msg)

    return prompt_content, errors


def _load_prompt_from_local(
    fail_on_error: bool = False,
) -> tuple[Optional[str], List[str]]:
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€

    Args:
        fail_on_error: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        tuple: (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ)

    Raises:
        RuntimeError: fail_on_error=Trueã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    errors = []
    prompt_content = None

    if PROMPT_STORAGE_TYPE.lower() == "local":
        prompt_path = Path(SYSTEM_PROMPT_PATH)
    else:
        prompt_path = Path(__file__).parent.parent / "prompts" / SYSTEM_PROMPT_FILENAME

    logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿: {prompt_path}")
    try:
        prompt_content = prompt_path.read_text(encoding="utf-8").strip()
        logger.info("ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except Exception as e:
        error_msg = f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}"
        logger.error(error_msg, exc_info=True)
        errors.append(error_msg)

        if fail_on_error:
            raise RuntimeError(
                f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_msg}"
            )

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æœ€å°é™ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt_content = "ã‚ãªãŸã¯å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")

    return prompt_content, errors


def load_system_prompt(force_reload: bool = False, fail_on_error: bool = False) -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
    åˆå›ã®ã¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã€ä»¥é™ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã™ã‚‹

    Args:
        force_reload: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†èª­è¾¼ã™ã‚‹å ´åˆã¯True
        fail_on_error: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        str: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹

    Raises:
        RuntimeError: fail_on_error=Trueã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Šã€å¼·åˆ¶å†èª­è¾¼ã§ãªã„å ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™
    if SYSTEM_PROMPT_FILENAME in _prompt_cache and not force_reload:
        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ©ç”¨: {SYSTEM_PROMPT_FILENAME}")
        return _prompt_cache[SYSTEM_PROMPT_FILENAME]

    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€
    prompt_content = None
    errors = []

    # S3ã‹ã‚‰èª­ã¿è¾¼ã‚€å ´åˆ
    if PROMPT_STORAGE_TYPE.lower() == "s3":
        prompt_content, s3_errors = _load_prompt_from_s3()
        errors.extend(s3_errors)

    # ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€å ´åˆï¼ˆS3èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã‚’å«ã‚€ï¼‰
    if not prompt_content:
        try:
            prompt_content, local_errors = _load_prompt_from_local(fail_on_error=False)
            errors.extend(local_errors)
        except RuntimeError as e:
            if fail_on_error:
                raise
            logger.error(f"ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)

    # ä¸¡æ–¹å¤±æ•—ã—ã€fail_on_errorãŒTrueã®å ´åˆã¯ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼
    if not prompt_content and fail_on_error:
        error_msg = "S3ã¨ãƒ­ãƒ¼ã‚«ãƒ«ã®ä¸¡æ–¹ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ"
        logger.error(error_msg)
        raise RuntimeError(f"{error_msg}: {'; '.join(errors)}")

    # prompt_contentãŒNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
    if prompt_content is None:
        prompt_content = "ã‚ãªãŸã¯å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")

    # ã“ã®æ™‚ç‚¹ã§prompt_contentã¯å¿…ãšstrå‹ãªã®ã§ã€æ˜ç¤ºçš„ã«å‹ã‚’ä¿è¨¼
    final_prompt: str = (
        prompt_content
        if prompt_content is not None
        else "ã‚ãªãŸã¯å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    )

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    _prompt_cache[SYSTEM_PROMPT_FILENAME] = final_prompt

    return final_prompt


def reload_system_prompt(fail_on_error: bool = False) -> bool:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åˆ¶çš„ã«å†èª­ã¿è¾¼ã¿ã™ã‚‹

    Args:
        fail_on_error: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆã¯True

    Raises:
        RuntimeError: fail_on_error=Trueã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        load_system_prompt(force_reload=True, fail_on_error=fail_on_error)
        return True
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        if fail_on_error:
            raise
        return False


class Sphene:
    """AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä¼šè©±ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, system_setting: str) -> None:
        """Spheneã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–

        Args:
            system_setting: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.system: ChatCompletionSystemMessageParam = {
            "role": "system",
            "content": system_setting,
        }
        self.input_list: List[ChatCompletionMessageParam] = [self.system]
        self.logs: List[ChatCompletion] = []
        # ä¼šè©±ã®æœ‰åŠ¹æœŸé™ã‚’è¨­å®šï¼ˆ30åˆ†ï¼‰
        self.last_interaction: Optional[datetime] = datetime.now()
        logger.info("Spheneã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–")

    def is_expired(self) -> bool:
        """ä¼šè©±ãŒæœŸé™åˆ‡ã‚Œã‹ã©ã†ã‹ã‚’åˆ¤å®š

        Returns:
            bool: Trueã®å ´åˆã¯æœŸé™åˆ‡ã‚Œ
        """
        if self.last_interaction is None:
            return False

        expiry_time = self.last_interaction + timedelta(
            minutes=MAX_CONVERSATION_AGE_MINUTES
        )
        return datetime.now() > expiry_time

    def update_interaction_time(self) -> None:
        """æœ€çµ‚ä¼šè©±æ™‚é–“ã‚’æ›´æ–°"""
        self.last_interaction = datetime.now()

    def trim_conversation_history(self) -> None:
        """é•·ããªã£ãŸä¼šè©±å±¥æ­´ã‚’æ•´ç†ã™ã‚‹"""
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ + å¾€å¾©Nå›åˆ†ã ã‘ä¿æŒ
        max_messages = 1 + (MAX_CONVERSATION_TURNS * 2)

        if len(self.input_list) > max_messages:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿æŒ
            system_message = self.input_list[0]
            # ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘ã‚’æ®‹ã™
            self.input_list = [system_message] + self.input_list[-(max_messages - 1) :]
            logger.info(
                f"ä¼šè©±å±¥æ­´ã‚’æ•´ç†ã—ã¾ã—ãŸï¼ˆæ®‹ã‚Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(self.input_list)}ï¼‰"
            )

    # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã¨å¯¾å¿œã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    _OPENAI_ERROR_HANDLERS: Dict[Type[APIError], Tuple[int, str, str]] = {
        AuthenticationError: (
            logging.ERROR,
            "OpenAI APIèªè¨¼ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®æ¥ç¶šè¨­å®šã§å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã¿ãŸã„â€¦ğŸ˜¢ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        PermissionDeniedError: (
            logging.ERROR,
            "OpenAI APIæ¨©é™ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã‚’ä½¿ã†ãŸã‚ã®æ¨©é™ãŒãªã„ã¿ãŸã„â€¦ğŸ˜¢ ç®¡ç†è€…ã«ç¢ºèªã—ã¦ã¿ã¦ã­ã€‚",
        ),
        NotFoundError: (
            logging.ERROR,
            "OpenAI APIãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚¨ãƒ©ãƒ¼: {}",
            f"ã”ã‚ã‚“ã­ã€æŒ‡å®šã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã€Œ{OPENAI_MODEL}ã€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã¿ãŸã„â€¦ğŸ˜¢",
        ),
        RateLimitError: (
            logging.WARNING,  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«
            "OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€ä»Šã¡ã‚‡ã£ã¨AIãŒæ··ã¿åˆã£ã¦ã‚‹ã¿ãŸã„â€¦ğŸ’¦ å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦è©±ã—ã‹ã‘ã¦ã¿ã¦ã­ï¼",
        ),
        APIConnectionError: (  # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã¯APIErrorã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã ãŒå€‹åˆ¥å‡¦ç†
            logging.ERROR,
            "OpenAI APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®æ¥ç¶šã§å•é¡ŒãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç¢ºèªã—ã¦ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        APITimeoutError: (  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚‚å€‹åˆ¥å‡¦ç†
            logging.ERROR,
            "OpenAI APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã‹ã‚‰ã®å¿œç­”ãŒæ™‚é–“å†…ã«è¿”ã£ã¦ã“ãªã‹ã£ãŸã¿ãŸã„â€¦ğŸ˜¢ ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã‚Œã‚‹ï¼Ÿ",
        ),
        InternalServerError: (
            logging.ERROR,
            "OpenAI APIã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIå´ã§ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã¿ãŸã„â€¦ğŸ˜¢ ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        APIStatusError: (  # ãã®ä»–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼
            logging.ERROR,
            "OpenAI APIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼ (Code: {}): {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®é€šä¿¡ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢",
        ),
        APIResponseValidationError: (
            logging.ERROR,
            "OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã‹ã‚‰ã®å¿œç­”ãŒãŠã‹ã—ã‹ã£ãŸã¿ãŸã„â€¦ğŸ¤” ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        BadRequestError: (
            logging.ERROR,
            "OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…å®¹ã«å•é¡ŒãŒã‚ã£ãŸã¿ãŸã„â€¦ğŸ˜¢ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¤‰ãˆã¦è©¦ã—ã¦ã¿ã¦ã­ã€‚",
        ),
        # APIError ã¯ä¸Šè¨˜ä»¥å¤–ã®APIé–¢é€£ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒ
        APIError: (
            logging.ERROR,
            "OpenAI APIé–¢é€£ã‚¨ãƒ©ãƒ¼: {}",
            "ã”ã‚ã‚“ã­ã€AIã¨ã®ã‚„ã‚Šå–ã‚Šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢",
        ),
    }

    def _handle_openai_error(self, error: Exception) -> str:
        """OpenAI APIã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™"""
        error_body = getattr(error, "body", str(error))
        status_code = getattr(error, "status_code", None)

        for error_type, (
            level,
            log_template,
            user_msg,
        ) in self._OPENAI_ERROR_HANDLERS.items():
            if isinstance(error, error_type):
                log_args = [error_body]
                if error_type is APIStatusError and status_code is not None:
                    log_args.insert(0, status_code)  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å…ˆé ­ã«è¿½åŠ 
                logger.log(level, log_template.format(*log_args), exc_info=True)
                return user_msg

        # ãƒãƒƒãƒ”ãƒ³ã‚°ã«ãªã„äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
        tb_str = traceback.format_exc()
        logger.critical(
            f"APIå‘¼ã³å‡ºã—ä¸­ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼å‹ ({type(error).__name__}): {str(error)}\n{tb_str}"
        )
        return "ã”ã‚ã‚“ï¼AIã¨ã®é€šä¿¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

    def _call_openai_api(self) -> Tuple[bool, str]:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—ã€çµæœã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™

        Returns:
            Tuple[bool, str]: (æˆåŠŸãƒ•ãƒ©ã‚°, å¿œç­”å†…å®¹ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        """
        try:
            # OpenAI APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            logger.info(f"OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆãƒ¢ãƒ‡ãƒ«: {OPENAI_MODEL}ï¼‰")
            result = aiclient.chat.completions.create(
                model=OPENAI_MODEL, messages=self.input_list
            )
            self.logs.append(result)

            # å¿œç­”ã‚’å‡¦ç†
            response_content = result.choices[0].message.content
            if response_content:
                logger.info(
                    f"OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {truncate_text(response_content)}"
                )
                return True, response_content
            else:
                logger.warning("OpenAI APIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™")
                return False, "ã”ã‚ã‚“ã­ã€AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã ã£ãŸã¿ãŸã„â€¦ğŸ¤”"

        except APIError as e:  # OpenAIã®APIé–¢é€£ã‚¨ãƒ©ãƒ¼ã‚’ã¾ã¨ã‚ã¦ã‚­ãƒ£ãƒƒãƒ
            user_message = self._handle_openai_error(e)
            return False, user_message
        except Exception as e:  # ãã®ä»–ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
            tb_str = traceback.format_exc()
            logger.critical(f"APIå‘¼ã³å‡ºã—ä¸­ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}\n{tb_str}")
            return False, "ã”ã‚ã‚“ï¼AIã¨ã®é€šä¿¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

    def input_message(self, input_text: Optional[str]) -> Optional[str]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã€AIã‹ã‚‰ã®å¿œç­”ã‚’è¿”ã™

        Args:
            input_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            Optional[str]: AIã‹ã‚‰ã®å¿œç­”ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        """
        if not isinstance(input_text, str) or not input_text.strip():
            logger.warning("å—ä¿¡ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç„¡åŠ¹ã§ã™")
            return None

        try:
            self.update_interaction_time()

            # å‹ã‚¬ãƒ¼ãƒ‰å¾Œã®å¤‰æ•°ã‚’å®šç¾©ã—ã¦ã‹ã‚‰ã‚¹ãƒ©ã‚¤ã‚·ãƒ³ã‚°
            input_str: str = input_text
            preview = truncate_text(input_str)
            logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡: {preview}")

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            user_message: ChatCompletionUserMessageParam = {
                "role": "user",
                "content": input_text,
            }
            self.input_list.append(user_message)

            # OpenAI APIå‘¼ã³å‡ºã—ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            success, content_or_error_msg = self._call_openai_api()

            if success:
                # æˆåŠŸã—ãŸå ´åˆã€å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¿”ã™
                assistant_message: ChatCompletionAssistantMessageParam = {
                    "role": "assistant",
                    "content": content_or_error_msg,  # æˆåŠŸæ™‚ã¯å¿œç­”å†…å®¹
                }
                self.input_list.append(assistant_message)
                self.trim_conversation_history()
                return content_or_error_msg
            else:
                # å¤±æ•—ã—ãŸå ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
                # å¤±æ•—æ™‚ã¯APIå‘¼ã³å‡ºã—å´ã§ãƒ­ã‚°å‡ºåŠ›æ¸ˆã¿
                return content_or_error_msg  # å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        except Exception as e:
            # APIå‘¼ã³å‡ºã—ä»¥å¤–ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
            tb_str = traceback.format_exc()
            logger.critical(f"input_messageå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}\n{tb_str}")
            return "ã”ã‚ã‚“ï¼å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ä¼šè©±ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¿æŒã™ã‚‹è¾æ›¸
user_conversations: DefaultDict[str, Sphene] = defaultdict(
    lambda: Sphene(system_setting=load_system_prompt())
)
