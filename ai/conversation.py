import base64
import json
import logging
import time
import traceback
import urllib.parse
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

import requests
from google.genai import types
from google.api_core import exceptions as google_exceptions

from ai.client import _get_genai_client, get_model_name
from config import (
    GEMINI_MODEL,
    SYSTEM_PROMPT_FILENAME,
    SYSTEM_PROMPT_PATH,
    ENABLE_GOOGLE_SEARCH_GROUNDING,
)
from ai.tools import get_tools, TOOL_FUNCTIONS
from log_utils.logger import logger

# å®šæ•°ã®å®šç¾©
MAX_CONVERSATION_AGE_MINUTES = 30
MAX_CONVERSATION_TURNS = 10
MAX_TOOL_CALL_ROUNDS = 3
MAX_IMAGE_BYTES = 5 * 1024 * 1024  # 5MB
IMAGE_REQUEST_TIMEOUT = (3, 5)  # (connect, read)
ALLOWED_IMAGE_DOMAINS = {"cdn.discordapp.com", "media.discordapp.net"}

def truncate_text(text: str, max_length: int = 30) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹"""
    if not text:
        return ""
    return text[:max_length] + "..." if len(text) > max_length else text

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_prompt_cache: dict[str, str] = {}

def _load_prompt_from_local(fail_on_error: bool = False) -> str | None:
    prompt_path = Path(SYSTEM_PROMPT_PATH)
    try:
        prompt_content = prompt_path.read_text(encoding="utf-8").strip()
        return prompt_content if prompt_content else None
    except Exception as e:
        if fail_on_error:
            raise RuntimeError(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}") from e
        return None

def _get_default_prompt() -> str:
    return "ã‚ãªãŸã¯å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

def load_system_prompt(force_reload: bool = False, fail_on_error: bool = False) -> str:
    if SYSTEM_PROMPT_FILENAME in _prompt_cache and not force_reload:
        return _prompt_cache[SYSTEM_PROMPT_FILENAME]
    prompt_content = _load_prompt_from_local(fail_on_error)
    if not prompt_content:
        prompt_content = _get_default_prompt()
    _prompt_cache[SYSTEM_PROMPT_FILENAME] = prompt_content
    return prompt_content

def _execute_tool_calls(tool_calls: list[types.FunctionCall]) -> list[types.Part]:
    """å…±é€šã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯"""
    results: list[types.Part] = []
    for call in tool_calls:
        function_name = call.name
        logger.info(f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {function_name}")
        func = TOOL_FUNCTIONS.get(function_name)
        if func is None:
            result_content = {"error": f"æœªçŸ¥ã®é–¢æ•°: {function_name}"}
        else:
            try:
                arguments = call.args
                result_content = func(**arguments)
            except Exception as e:
                logger.error(f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {function_name}: {e}", exc_info=True)
                result_content = {"error": "ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"}

        if isinstance(result_content, str):
            try:
                result_dict = json.loads(result_content)
            except:
                result_dict = {"content": result_content}
        else:
            result_dict = result_content

        results.append(
            types.Part.from_function_response(
                name=function_name,
                response=result_dict,
            )
        )
    return results

def _handle_api_error(error: Exception) -> str:
    if "404" in str(error):
        return f"ã”ã‚ã‚“ã­ã€æŒ‡å®šã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã€Œ{GEMINI_MODEL}ã€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã“ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ä½¿ãˆãªã„ã¿ãŸã„â€¦ğŸ˜¢"
    if "429" in str(error):
        return "ã”ã‚ã‚“ã­ã€ä»Šã¡ã‚‡ã£ã¨AIãŒæ··ã¿åˆã£ã¦ã‚‹ã¿ãŸã„â€¦ğŸ’¦ å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦è©±ã—ã‹ã‘ã¦ã¿ã¦ã­ï¼"
    logger.error(f"APIã‚¨ãƒ©ãƒ¼: {error}", exc_info=True)
    return "ã”ã‚ã‚“ï¼AIã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

def _call_genai_with_tools(
    contents: list[types.Content],
    system_instruction: str,
) -> tuple[bool, str, list[types.Content]]:
    """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ«ãƒ¼ãƒ—ã‚’å«ã‚€GenAIå‘¼ã³å‡ºã— (å…±é€šãƒ­ã‚¸ãƒƒã‚¯)"""
    client = _get_genai_client()
    model_id = get_model_name()
    
    # ãƒ„ãƒ¼ãƒ«è¨­å®š
    tools = get_tools()
    if ENABLE_GOOGLE_SEARCH_GROUNDING:
        tools.append(types.Tool(google_search_retrieval=types.GoogleSearchRetrieval()))

    # contentsãƒªã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦æ“ä½œã™ã‚‹
    local_history = list(contents)

    for round_num in range(MAX_TOOL_CALL_ROUNDS + 1):
        logger.info(f"GenAIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ (ãƒ©ã‚¦ãƒ³ãƒ‰ {round_num + 1}, ãƒ¢ãƒ‡ãƒ«: {model_id})")
        
        try:
            response = client.models.generate_content(
                model=model_id,
                contents=local_history,
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    tools=tools,
                    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True), # æ‰‹å‹•ãƒ«ãƒ¼ãƒ—
                ),
            )
        except Exception as e:
            return False, _handle_api_error(e), local_history

        if not response.candidates:
            return False, "AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã ã£ãŸã‚ˆâ€¦ğŸ¤”", local_history

        resp_content = response.candidates[0].content
        local_history.append(resp_content)

        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹ã‹ç¢ºèª
        function_calls = [p.function_call for p in resp_content.parts if p.function_call]
        
        if function_calls:
            logger.info(f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æ¤œå‡º: {len(function_calls)}ä»¶")
            tool_results = _execute_tool_calls(function_calls)
            local_history.append(types.Content(role="user", parts=tool_results))
            continue

        # ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’æŠ½å‡º
        text_parts = [p.text for p in resp_content.parts if p.text]
        if text_parts:
            final_text = "".join(text_parts)
            logger.debug(f"GenAIå¿œç­”å—ä¿¡: {truncate_text(final_text)}")
            return True, final_text, local_history
        
        return False, "å¿œç­”ã‚’èª­ã¿å–ã‚Œãªã‹ã£ãŸã‚ˆâ€¦ğŸ˜¢", local_history

    return False, "å‡¦ç†ãŒè¤‡é›‘ã™ãã¦è«¦ã‚ã¡ã‚ƒã£ãŸâ€¦ğŸ˜¢", local_history

class Sphene:
    """AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä¼šè©±ç®¡ç†ã‚¯ãƒ©ã‚¹ (google-genaiç‰ˆ)"""

    def __init__(self, system_setting: str) -> None:
        self.system_prompt = system_setting
        self.history: list[types.Content] = []
        self.last_interaction: datetime | None = datetime.now()
        logger.info("Spheneã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ– (Google Gen AI SDK)")

    def is_expired(self) -> bool:
        if self.last_interaction is None:
            return False
        expiry_time = self.last_interaction + timedelta(minutes=MAX_CONVERSATION_AGE_MINUTES)
        return datetime.now() > expiry_time

    def update_interaction_time(self) -> None:
        self.last_interaction = datetime.now()

    def trim_conversation_history(self) -> None:
        if len(self.history) <= (MAX_CONVERSATION_TURNS * 2):
            return
        recent_history = self.history[-(MAX_CONVERSATION_TURNS * 2) :]
        start_idx = 0
        for i, content in enumerate(recent_history):
            if content.role == "user":
                start_idx = i
                break
        self.history = recent_history[start_idx:]

    def input_message(self, input_text: str | None, image_urls: list[str] | None = None) -> str | None:
        if not isinstance(input_text, str) or not input_text.strip():
            return None

        try:
            self.update_interaction_time()
            parts = [types.Part.from_text(text=input_text)]
            
            if image_urls:
                for url in image_urls:
                    try:
                        parsed = urllib.parse.urlparse(url)
                        if parsed.hostname not in ALLOWED_IMAGE_DOMAINS:
                            logger.warning(f"è¨±å¯ã•ã‚Œã¦ã„ãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ç”»åƒã‚’ã‚¹ã‚­ãƒƒãƒ—: {url}")
                            continue

                        with requests.get(url, timeout=IMAGE_REQUEST_TIMEOUT, stream=True) as resp:
                            resp.raise_for_status()

                            content_type = resp.headers.get("Content-Type", "")
                            if not content_type.startswith("image/"):
                                logger.warning(f"ç”»åƒä»¥å¤–ã®Content-Typeã‚’æ¤œå‡º: {url} ({content_type})")
                                continue

                            content_length = resp.headers.get("Content-Length")
                            try:
                                if content_length and int(content_length) > MAX_IMAGE_BYTES:
                                    logger.warning(f"ç”»åƒã‚µã‚¤ã‚ºè¶…éã§ã‚¹ã‚­ãƒƒãƒ—: {url} ({content_length} bytes)")
                                    continue
                            except (ValueError, TypeError):
                                logger.warning(f"ä¸æ­£ãªContent-Length: {url} ({content_length})")

                            data = bytearray()
                            for chunk in resp.iter_content(chunk_size=64 * 1024):
                                if not chunk:
                                    continue
                                data.extend(chunk)
                                if len(data) > MAX_IMAGE_BYTES:
                                    logger.warning(f"ç”»åƒã‚µã‚¤ã‚ºä¸Šé™è¶…éã§ä¸­æ–­: {url} ({len(data)} bytes)")
                                    data = bytearray()
                                    break

                            if not data:
                                continue

                            parts.append(
                                types.Part.from_bytes(
                                    data=bytes(data),
                                    mime_type=content_type,
                                )
                            )
                    except Exception as e:
                        logger.error(f"ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {url} - {e}")

            self.history.append(types.Content(role="user", parts=parts))
            
            # å…±é€šãƒ­ã‚¸ãƒƒã‚¯ã§å‘¼ã³å‡ºã—
            success, response, updated_history = _call_genai_with_tools(
                contents=self.history,
                system_instruction=self.system_prompt
            )
            
            # å±¥æ­´ã‚’æ›´æ–°
            self.history = updated_history
            
            if success:
                self.trim_conversation_history()
            return response
        except Exception as e:
            logger.critical(f"input_messageã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return "äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸ...ğŸ˜¢"

def generate_contextual_response(channel_context: str, trigger_message: str, system_prompt: str | None = None) -> str | None:
    try:
        if system_prompt is None:
            system_prompt = load_system_prompt()
        
        # ãƒ„ãƒ¼ãƒ«ã‚’ç©æ¥µçš„ã«ä½¿ã†ã‚ˆã†ã«æŒ‡ç¤ºã‚’è¿½åŠ ï¼
        instruction = (
            f"{system_prompt}\n\n"
            f"--- ãƒãƒ£ãƒ³ãƒãƒ«ã®ç›´è¿‘ã®ä¼šè©± ---\n{channel_context}\n---\n"
            f"è‡ªç„¶ã«ä¼šè©±ã«å‚åŠ ã—ã¦ã­ã€‚ã‚‚ã—çŸ¥ã‚‰ãªã„ã“ã¨ã‚„æœ€æ–°ã®æƒ…å ±ãŒå¿…è¦ãªã‚‰ã€ç©æ¥µçš„ã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦èª¿ã¹ã¦ã­ï¼"
        )
        
        # 1-shot ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆ
        contents = [types.Content(role="user", parts=[types.Part.from_text(text=trigger_message)])]
        
        # å…±é€šãƒ­ã‚¸ãƒƒã‚¯ã§å‘¼ã³å‡ºã—ï¼ˆãƒ„ãƒ¼ãƒ«ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ï¼ï¼‰
        success, response, _ = _call_genai_with_tools(
            contents=contents,
            system_instruction=instruction
        )
        
        return response if success else None
    except Exception as e:
        logger.error(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None

def reload_system_prompt(fail_on_error: bool = False) -> bool:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åˆ¶çš„ã«å†èª­ã¿è¾¼ã¿ã™ã‚‹"""
    try:
        load_system_prompt(force_reload=True, fail_on_error=fail_on_error)
        return True
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        if fail_on_error:
            raise
        return False

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ä¼šè©±ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¿æŒã™ã‚‹è¾æ›¸
user_conversations: defaultdict[str, Sphene] = defaultdict(
    lambda: Sphene(system_setting=load_system_prompt())
)

def cleanup_expired_conversations() -> int:
    """æœŸé™åˆ‡ã‚Œã®ä¼šè©±ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰å‰Šé™¤ã™ã‚‹"""
    expired_ids = [
        user_id for user_id, api in user_conversations.items() if api.is_expired()
    ]
    for user_id in expired_ids:
        del user_conversations[user_id]

    if expired_ids:
        logger.info(f"æœŸé™åˆ‡ã‚Œã®ä¼šè©±ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: {len(expired_ids)}ä»¶")
    return len(expired_ids)
